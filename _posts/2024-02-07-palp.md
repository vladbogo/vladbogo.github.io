---
title: "PALP: Prompt Aligned Personalization"
categories:
  - Blog
---
PALP: Prompt Aligned Personalization is a new paper from Google that allows the creation of images with complex and intricate prompts. Traditional text-to-image AI struggles with complex prompts and personal subjects. The trade-off between personalization and prompt fidelity has been a significant hurdle. PALP aims to address this.

![](https://media.licdn.com/dms/image/D4E12AQG99K87cfXapw/article-inline_image-shrink_400_744/0/1707339519167?e=1712793600&v=beta&t=uqoCnP4IkIuwD35OeUzpErNd6Czi6X7pyq0R3lPVEqQ)

The goal of Prompt aligned personalization is to allow the generation of complex scenes, including all elements defined in a conditional prompt

PALP's core innovation lies in its unique method of maintaining strict alignment with the textual prompt while incorporating personal or subjective elements into the generated images. Unlike traditional text-to-image models, PALP ensures that the final output not only contains the subject but is also in perfect harmony with the specified style, ambiance, and context described in the prompt. In other words, PALP improves text alignment, enabling the creation of personalized images.

![](https://media.licdn.com/dms/image/D4E12AQG9vRk535DBRA/article-inline_image-shrink_400_744/0/1707339686778?e=1712793600&v=beta&t=vnZeqcyuEb8oTlzYTBzo6OmSWZ9BalNsBVVwsZ00J6g)

PALP architecture

The primary goal of PALP is to generate images that accurately show one subject while adding all the elements that are present in the prompt. So, for example, let's assume the input image is a photo of a cat and the prompt is "A sketch of [my cat] in Paris". The goal of PALP is to generate the same cat that is shown in the photo, while incorporating all other elements from the prompt - in this case a "sketch" and "Paris". The PALP framework uses a two path approach to image personalization and prompt alignment. It combines a _personalization path_, fine-tuning pre-trained models with a reconstruction loss for the subject, with a _prompt-alignment branch_ that uses score sampling to align images with specific prompts like "A sketch of a cat."

## Results

The PALP model showcases very good results for image personalization and prompt alignment both qualitatively and quantitatively.

![](https://media.licdn.com/dms/image/D4E12AQGxW4oCuxUL9g/article-inline_image-shrink_1000_1488/0/1707341319553?e=1712793600&v=beta&t=vTwXoeMMYbOJ3-VaNqrGFQSOT2pqemp3OM9-dBIB6Uk)

Multi-subject personalization

![](https://media.licdn.com/dms/image/D4E12AQH1z-4Oq_UhEw/article-inline_image-shrink_400_744/0/1707340625828?e=1712793600&v=beta&t=g5H6pqymeqEV_m4Jn04QAyLcwsNKPaypoyM862yMdWQ)

Comparison with other methods

The authors also conduct a user study, where PALP demonstrated a significant improvement in both text alignment, with a 91.2% success rate in maintaining elements from the prompt within the generated image, and personalization, achieving a 72.1% similarity rate between the subject and the main subject in the generated image. These findings underscore PALP's ability to produce images that are not only more aligned with complex prompts but also maintain a high degree of fidelity to the personal subject, setting a new benchmark for personalized content creation.

![](https://media.licdn.com/dms/image/D4E12AQFW72rFqCmP3w/article-inline_image-shrink_400_744/0/1707340711257?e=1712793600&v=beta&t=bGvnY68scvqg5_JkGoz-V_BV_3w_PEYT1GyoXArZTFM)

User study

## Conclusion

In conclusion, the PALP framework is a new method for image generation that shows very promising results. Its dual-path approach not only fine-tunes images to ensure subject consistency but also closely follows and depicts all elements from the prompt. For more details, please consult the full paper [https://arxiv.org/abs/2401.06105](https://arxiv.org/abs/2401.06105) and the project page [https://prompt-aligned.github.io](https://prompt-aligned.github.io/).

Congratulations to the authors for their great work!

Arar, Moab, et al. "PALP: Prompt Aligned Personalization of Text-to-Image Models." _arXiv preprint arXiv:2401.06105_ (2024).
